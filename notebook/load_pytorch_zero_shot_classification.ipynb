{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Huggingface Pytorch Fill Mask Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upickle_2.12/0.9.5/upickle_2.12-0.9.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upickle_2.12/0.9.5/upickle_2.12-0.9.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/ujson_2.12/0.9.5/ujson_2.12-0.9.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upack_2.12/0.9.5/upack_2.12-0.9.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upickle-implicits_2.12/0.9.5/upickle-implicits_2.12-0.9.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/ujson_2.12/0.9.5/ujson_2.12-0.9.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upack_2.12/0.9.5/upack_2.12-0.9.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upickle-implicits_2.12/0.9.5/upickle-implicits_2.12-0.9.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upickle-core_2.12/0.9.5/upickle-core_2.12-0.9.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upickle-core_2.12/0.9.5/upickle-core_2.12-0.9.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/ujson_2.12/0.9.5/ujson_2.12-0.9.5.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upickle-core_2.12/0.9.5/upickle-core_2.12-0.9.5.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upack_2.12/0.9.5/upack_2.12-0.9.5-sources.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upickle-implicits_2.12/0.9.5/upickle-implicits_2.12-0.9.5.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upack_2.12/0.9.5/upack_2.12-0.9.5.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upickle-implicits_2.12/0.9.5/upickle-implicits_2.12-0.9.5-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upack_2.12/0.9.5/upack_2.12-0.9.5-sources.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upickle-core_2.12/0.9.5/upickle-core_2.12-0.9.5-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upickle-core_2.12/0.9.5/upickle-core_2.12-0.9.5.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/ujson_2.12/0.9.5/ujson_2.12-0.9.5-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/ujson_2.12/0.9.5/ujson_2.12-0.9.5.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upickle_2.12/0.9.5/upickle_2.12-0.9.5-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upickle-core_2.12/0.9.5/upickle-core_2.12-0.9.5-sources.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upickle_2.12/0.9.5/upickle_2.12-0.9.5.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upickle-implicits_2.12/0.9.5/upickle-implicits_2.12-0.9.5-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upack_2.12/0.9.5/upack_2.12-0.9.5.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/ujson_2.12/0.9.5/ujson_2.12-0.9.5-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upickle-implicits_2.12/0.9.5/upickle-implicits_2.12-0.9.5.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upickle_2.12/0.9.5/upickle_2.12-0.9.5-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upickle_2.12/0.9.5/upickle_2.12-0.9.5.jar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                  \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                     \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                        \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                     \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                           \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                              \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                           \u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`ai.djl:api:0.17.0`\n",
    "import $ivy.`ai.djl.huggingface:tokenizers:0.17.0`\n",
    "import $ivy.`ai.djl.pytorch:pytorch-model-zoo:0.17.0`\n",
    "import $ivy.`ai.djl.pytorch:pytorch-engine:0.17.0`\n",
    "import $ivy.`org.slf4j:slf4j-api:1.7.36`\n",
    "import $ivy.`org.slf4j:slf4j-simple:1.7.36`\n",
    "import $ivy.`com.lihaoyi::upickle:0.9.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io.IOException\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.file.{Files, Paths}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.util\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.modality.Classifications\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.modality.nlp.DefaultVocabulary\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.modality.nlp.bert.BertTokenizer\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.modality.nlp.Vocabulary\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.ndarray.NDList\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.repository.zoo.Criteria\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.training.util.{DownloadUtils, ProgressBar}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.translate.{Batchifier, Translator, TranslatorContext}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.huggingface.tokenizers.HuggingFaceTokenizer\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.io.IOException\n",
    "import java.nio.file.{Files, Paths}\n",
    "import java.util\n",
    "\n",
    "import ai.djl.modality.Classifications\n",
    "import ai.djl.modality.nlp.DefaultVocabulary\n",
    "import ai.djl.modality.nlp.bert.BertTokenizer\n",
    "import ai.djl.modality.nlp.Vocabulary\n",
    "import ai.djl.ndarray.NDList\n",
    "import ai.djl.repository.zoo.Criteria\n",
    "import ai.djl.training.util.{DownloadUtils, ProgressBar}\n",
    "import ai.djl.translate.{Batchifier, Translator, TranslatorContext}\n",
    "import ai.djl.huggingface.tokenizers.HuggingFaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mPredictedLabel\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class PredictedLabel(label: String, score: Double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io.{IOException, InputStreamReader}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.net.URL\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.charset.StandardCharsets\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.util\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.util.JsonUtils\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.google.gson.annotations.SerializedName\n",
       "\n",
       "\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mVocabParser\u001b[39m\n",
       "defined \u001b[32mobject\u001b[39m \u001b[36mVocabParser\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.io.{IOException, InputStreamReader}\n",
    "import java.net.URL\n",
    "import java.nio.charset.StandardCharsets\n",
    "import java.util\n",
    "\n",
    "import ai.djl.util.JsonUtils\n",
    "import com.google.gson.annotations.SerializedName\n",
    "\n",
    "class VocabParser {\n",
    "  @SerializedName(\"idx_to_token\")\n",
    "  var idx2token: util.Map[String, Long] = _\n",
    "\n",
    "}\n",
    "\n",
    "object VocabParser {\n",
    "  def parseToken(file: URL) = {\n",
    "    try {\n",
    "      val is = file.openStream()\n",
    "      val reader = new InputStreamReader(is, StandardCharsets.UTF_8)\n",
    "      JsonUtils.GSON.fromJson(reader, classOf[VocabParser]).idx2token\n",
    "    } catch {\n",
    "      case e: IOException => throw new IllegalArgumentException(\"Invalid url: \" + file, e)\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mjava.net.URL\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36murl\u001b[39m: \u001b[32mURL\u001b[39m = file:/Users/donglin/Workspace/deep-learning-scala/notebook/../build/huggingface/zero-shot-classification/pytorch/bart-large-mnli/vocab.json"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.net.URL\n",
    "\n",
    "val url = Paths.get(\"../build/huggingface/zero-shot-classification/pytorch/bart-large-mnli/vocab.json\").toUri.toURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.util.JsonUtils\u001b[39m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ai.djl.util.JsonUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io.{IOException, InputStreamReader}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.charset.StandardCharsets\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mis\u001b[39m: \u001b[32mjava\u001b[39m.\u001b[32mio\u001b[39m.\u001b[32mInputStream\u001b[39m = java.io.BufferedInputStream@695cbea8\n",
       "\u001b[36mreader\u001b[39m: \u001b[32mInputStreamReader\u001b[39m = java.io.InputStreamReader@79610fff"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.io.{IOException, InputStreamReader}\n",
    "import java.nio.charset.StandardCharsets\n",
    "\n",
    "val is = url.openStream()\n",
    "val reader = new InputStreamReader(is, StandardCharsets.UTF_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31mcom.google.gson.JsonSyntaxException: com.google.gson.stream.MalformedJsonException: Expected value at line 1 column 1 path $\u001b[39m\n  com.google.gson.Gson.fromJson(\u001b[32mGson.java\u001b[39m:\u001b[32m1006\u001b[39m)\n  com.google.gson.Gson.fromJson(\u001b[32mGson.java\u001b[39m:\u001b[32m929\u001b[39m)\n  ammonite.$sess.cmd17$Helper.<init>(\u001b[32mcmd17.sc\u001b[39m:\u001b[32m1\u001b[39m)\n  ammonite.$sess.cmd17$.<init>(\u001b[32mcmd17.sc\u001b[39m:\u001b[32m7\u001b[39m)\n  ammonite.$sess.cmd17$.<clinit>(\u001b[32mcmd17.sc\u001b[39m:\u001b[32m-1\u001b[39m)\n\u001b[31mcom.google.gson.stream.MalformedJsonException: Expected value at line 1 column 1 path $\u001b[39m\n  com.google.gson.stream.JsonReader.syntaxError(\u001b[32mJsonReader.java\u001b[39m:\u001b[32m1597\u001b[39m)\n  com.google.gson.stream.JsonReader.doPeek(\u001b[32mJsonReader.java\u001b[39m:\u001b[32m590\u001b[39m)\n  com.google.gson.stream.JsonReader.peek(\u001b[32mJsonReader.java\u001b[39m:\u001b[32m425\u001b[39m)\n  com.google.gson.Gson.fromJson(\u001b[32mGson.java\u001b[39m:\u001b[32m987\u001b[39m)\n  com.google.gson.Gson.fromJson(\u001b[32mGson.java\u001b[39m:\u001b[32m929\u001b[39m)\n  ammonite.$sess.cmd17$Helper.<init>(\u001b[32mcmd17.sc\u001b[39m:\u001b[32m1\u001b[39m)\n  ammonite.$sess.cmd17$.<init>(\u001b[32mcmd17.sc\u001b[39m:\u001b[32m7\u001b[39m)\n  ammonite.$sess.cmd17$.<clinit>(\u001b[32mcmd17.sc\u001b[39m:\u001b[32m-1\u001b[39m)"
     ]
    }
   ],
   "source": [
    "JsonUtils.GSON.fromJson(reader, classOf[util.Map[String, Long]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mjsonStr\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"{\\\"<s>\\\":0,\\\"<pad>\\\":1,\\\"</s>\\\":2,\\\"<unk>\\\":3,\\\".\\\":4,\\\"\\u0120the\\\":5,\\\",\\\":6,\\\"\\u0120to\\\":7,\\\"\\u0120and\\\":8,\\\"\\u0120of\\\":9,\\\"\\u0120a\\\":10,\\\"\\u0120in\\\":11,\\\"-\\\":12,\\\"\\u0120for\\\":13,\\\"\\u0120that\\\":14,\\\"\\u0120on\\\":15,\\\"\\u0120is\\\":16,\\\"\\u00e2\\u0122\\\":17,\\\"'s\\\":18,\\\"\\u0120with\\\":19,\\\"\\u0120The\\\":20,\\\"\\u0120was\\\":21,\\\"\\u0120\\\\\\\"\\\":22,\\\"\\u0120at\\\":23,\\\"\\u0120it\\\":24,\\\"\\u0120as\\\":25,\\\"\\u0120said\\\":26,\\\"\\u013b\\\":27,\\\"\\u0120be\\\":28,\\\"s\\\":29,\\\"\\u0120by\\\":30,\\\"\\u0120from\\\":31,\\\"\\u0120are\\\":32,\\\"\\u0120have\\\":33,\\\"\\u0120has\\\":34,\\\":\\\":35,\\\"\\u0120(\\\":36,\\\"\\u0120he\\\":37,\\\"\\u0120I\\\":38,\\\"\\u0120his\\\":39,\\\"\\u0120will\\\":40,\\\"\\u0120an\\\":41,\\\"\\u0120this\\\":42,\\\")\\\":43,\\\"\\u0120\\u00e2\\u0122\\\":44,\\\"\\u0120not\\\":45,\\\"\\u013f\\\":46,\\\"\\u0120you\\\":47,\\\"\\u013e\\\":48,\\\"\\u0120their\\\":49,\\\"\\u0120or\\\":50,\\\"\\u0120they\\\":51,\\\"\\u0120we\\\":52,\\\"\\u0120but\\\":53,\\\"\\u0120who\\\":54,\\\"\\u0120more\\\":55,\\\"\\u0120had\\\":56,\\\"\\u0120been\\\":57,\\\"\\u0120were\\\":58,\\\"\\u0120about\\\":59,\\\",\\\\\\\"\\\":60,\\\"\\u0120which\\\":61,\\\"\\u0120up\\\":62,\\\"\\u0120its\\\":63,\\\"\\u0120can\\\":64,\\\"\\u0120one\\\":65,\\\"\\u0120out\\\":66,\\\"\\u0120also\\\":67,\\\"\\u0120$\\\":68,\\\"\\u0120her\\\":69,\\\"\\u0120all\\\":70,\\\"\\u0120after\\\":71,\\\".\\\\\\\"\\\":72,\\\"/\\\":73,\\\"\\u0120would\\\":74,\\\"'t\\\":75,\\\"\\u0120year\\\":76,\\\"\\u0120when\\\":77,\\\"\\u0120first\\\":78,\\\"\\u0120she\\\":79,\\\"\\u0120two\\\":80,\\\"\\u0120over\\\":81,\\\"\\u0120people\\\":82,\\\"\\u0120A\\\":83,\\\"\\u0120our\\\":84,\\\"\\u0120It\\\":85,\\\"\\u0120time\\\":86,\\\"\\u0120than\\\":87,\\\"\\u0120into\\\":88,\\\"\\u0120there\\\":89,\\\"t\\\":90,\\\"\\u0120He\\\":91,\\\"\\u0120new\\\":92,\\\"\\u0120\\u00e2\\u0122\\u0136\\\":93,\\\"\\u0120last\\\":94,\\\"\\u0120just\\\":95,\\\"\\u0120In\\\":96,\\\"\\u0120other\\\":97,\\\"\\u0120so\\\":98,\\\"\\u0120what\\\":99,\\\"I\\\":100,\\\"\\u0120like\\\":101,\\\"a\\\":102,\\\"\\u0120some\\\":103,\\\"S\\\":104,\\\"\\u00c3\\u00ab\\\":105,\\\"\\u0120them\\\":106,\\\"\\u0120years\\\":107,\\\"'\\\":108,\\\"\\u0120do\\\":109,\\\"\\u0120your\\\":110,\\\"\\u0120-\\\":111,\\\"\\u01201\\\":112,\\\"\\\\\\\"\\\":113,\\\"\\u0120if\\\":114,\\\"\\u0120could\\\":115,\\\"?\\\":116,\\\"\\u0120no\\\":117,\\\"i\\\":118,\\\"m\\\":119,\\\"\\u0120get\\\":120,\\\"\\u0120U\\\":121,\\\"\\u0120now\\\":122,\\\"\\u0120him\\\":123,\\\"\\u0120back\\\":124,\\\"\\u0120But\\\":125,\\\"\\u0120\\u00e2\\u0122\\u0135\\\":126,\\\"\\u0120my\\\":127,\\\"\\u0120'\\\":128,\\\"\\u0120only\\\":129,\\\"\\u0120three\\\":130,\\\";\\\":131,\\\"\\u01202\\\":132,\\\"The\\\":133,\\\"1\\\":134,\\\"\\u0120percent\\\":135,\\\"\\u0120against\\\":136,\\\"\\u0120before\\\":137,\\\"\\u0120company\\\":138,\\\"o\\\":139,\\\"\\u0120Trump\\\":140,\\\"\\u0120how\\\":141,\\\"\\u0120because\\\":142,\\\"\\u0120any\\\":143,\\\"\\u0120most\\\":144,\\\"\\u0120being\\\":145,\\\"\\u0120make\\\":146,\\\"\\u0120where\\\":147,\\\"\\u0120during\\\":148,\\\"\\u0120through\\\":149,\\\"\\u0120while\\\":150,\\\"000\\\":151,\\\"\\u0120This\\\":152,\\\"\\u0120million\\\":153,\\\"ing\\\":154,\\\"\\u01203\\\":155,\\\"\\u0120made\\\":156,\\\"\\u0120well\\\":157,\\\"\\u012010\\\":158,\\\"\\u0120down\\\":159,\\\"\\u0120off\\\":160,\\\"\\u0120says\\\":161,\\\"\\u0120me\\\":162,\\\"\\u0120B\\\":163,\\\"\\u0120going\\\":164,\\\"\\u0120team\\\":165,\\\"\\u0120We\\\":166,\\\"\\u0120those\\\":167,\\\"\\u0120government\\\":168,\\\"\\u0120way\\\":169,\\\"We\\\":170,\\\"\\u0120many\\\":171,\\\"\\u0120then\\\":172,\\\"\\u0120work\\\":173,\\\"\\u0120told\\\":174,\\\"com\\\":175,\\\"2\\\":176,\\\"\\u0120game\\\":177,\\\"\\u0120And\\\":178,\\\"in\\\":179,\\\"year\\\":180,\\\"\\u0120p\\\":181,\\\"\\u0120very\\\":182,\\\"\\u0120day\\\":183,\\\"\\u0120home\\\":184,\\\"\\u0120take\\\":185,\\\"\\u0120week\\\":186,\u001b[39m..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val jsonStr = scala.io.Source.fromFile(url.getPath).mkString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mvocab\u001b[39m: \u001b[32mSeq\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[32m\"<s>\"\u001b[39m,\n",
       "  \u001b[32m\"<pad>\"\u001b[39m,\n",
       "  \u001b[32m\"</s>\"\u001b[39m,\n",
       "  \u001b[32m\"<unk>\"\u001b[39m,\n",
       "  \u001b[32m\".\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120the\"\u001b[39m,\n",
       "  \u001b[32m\",\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120to\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120and\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120of\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120a\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120in\"\u001b[39m,\n",
       "  \u001b[32m\"-\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120for\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120that\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120on\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120is\"\u001b[39m,\n",
       "  \u001b[32m\"\\u00e2\\u0122\"\u001b[39m,\n",
       "  \u001b[32m\"'s\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120with\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120The\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120was\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120\\\"\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120at\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120it\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120as\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120said\"\u001b[39m,\n",
       "  \u001b[32m\"\\u013b\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120be\"\u001b[39m,\n",
       "  \u001b[32m\"s\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120by\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120from\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120are\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120have\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120has\"\u001b[39m,\n",
       "  \u001b[32m\":\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120(\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120he\"\u001b[39m,\n",
       "..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val vocab = ujson.read(jsonStr).obj.keySet.toSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres11\u001b[39m: \u001b[32mcollection\u001b[39m.\u001b[32mSet\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mSet\u001b[39m(\n",
       "  \u001b[32m\"<s>\"\u001b[39m,\n",
       "  \u001b[32m\"<pad>\"\u001b[39m,\n",
       "  \u001b[32m\"</s>\"\u001b[39m,\n",
       "  \u001b[32m\"<unk>\"\u001b[39m,\n",
       "  \u001b[32m\".\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120the\"\u001b[39m,\n",
       "  \u001b[32m\",\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120to\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120and\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120of\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120a\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120in\"\u001b[39m,\n",
       "  \u001b[32m\"-\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120for\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120that\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120on\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120is\"\u001b[39m,\n",
       "  \u001b[32m\"\\u00e2\\u0122\"\u001b[39m,\n",
       "  \u001b[32m\"'s\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120with\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120The\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120was\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120\\\"\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120at\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120it\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120as\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120said\"\u001b[39m,\n",
       "  \u001b[32m\"\\u013b\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120be\"\u001b[39m,\n",
       "  \u001b[32m\"s\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120by\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120from\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120are\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120have\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120has\"\u001b[39m,\n",
       "  \u001b[32m\":\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120(\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120he\"\u001b[39m,\n",
       "..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.obj.map {case (key, value) => }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31mjava.lang.NullPointerException\u001b[39m\n  ai.djl.modality.nlp.DefaultVocabulary.<init>(\u001b[32mDefaultVocabulary.java\u001b[39m:\u001b[32m63\u001b[39m)\n  ai.djl.modality.nlp.DefaultVocabulary$Builder.build(\u001b[32mDefaultVocabulary.java\u001b[39m:\u001b[32m360\u001b[39m)\n  ammonite.$sess.cmd6$Helper.<init>(\u001b[32mcmd6.sc\u001b[39m:\u001b[32m5\u001b[39m)\n  ammonite.$sess.cmd6$.<init>(\u001b[32mcmd6.sc\u001b[39m:\u001b[32m7\u001b[39m)\n  ammonite.$sess.cmd6$.<clinit>(\u001b[32mcmd6.sc\u001b[39m:\u001b[32m-1\u001b[39m)"
     ]
    }
   ],
   "source": [
    "val path = Paths.get(\"/Users/donglin/Workspace/deep-learning-scala/build/huggingface/zero-shot-classification/pytorch/bart-large-mnli/vocab.json\").toUri.toURL\n",
    "// val vocabulary = DefaultVocabulary.builder\n",
    "//   .optMinFrequency(1)\n",
    "//   .addFromCustomizedFile(path, VocabParser.parseToken)\n",
    "//   .optUnknownToken(\"[UNK]\")\n",
    "//   .build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mHFBertFillMaskTranslator\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class HFZeroShotClsTranslator extends Translator[String, Seq[PredictedLabel]] {\n",
    "\n",
    "  private var vocabulary: DefaultVocabulary = _\n",
    "  private var tokenizer: HuggingFaceTokenizer = _\n",
    "  private var tokenList: Array[String] = _\n",
    "  private final val MaskToken = \"[MASK]\"\n",
    "  private final val TopK = 5\n",
    "\n",
    "  override def prepare(ctx: TranslatorContext): Unit = {\n",
    "    val path = Paths.get(\"../build/huggingface/fill_mask/pytorch/bert-base-uncased/vocab.txt\")\n",
    "    vocabulary = DefaultVocabulary.builder\n",
    "      .optMinFrequency(1)\n",
    "      .addFromTextFile(path)\n",
    "      .optUnknownToken(\"[UNK]\")\n",
    "      .build\n",
    "    tokenizer = HuggingFaceTokenizer.newInstance(\"bert-base-uncased\")\n",
    "  }\n",
    "\n",
    "  override def processInput(ctx: TranslatorContext, input: String): NDList = {\n",
    "    val token = tokenizer.encode(input.toLowerCase().replace(MaskToken.toLowerCase(), MaskToken))\n",
    "    // get the encoded tokens that would be used in precessOutput\n",
    "    tokenList = token.getTokens\n",
    "    // map the tokens(String) to indices(long)\n",
    "\n",
    "    val manager = ctx.getNDManager\n",
    "    val indices = tokenList.map(vocabulary.getIndex)\n",
    "    val attentionMask = token.getAttentionMask.map(i => i)\n",
    "    val indicesArray = manager.create(indices)\n",
    "    val attentionMaskArray = manager.create(attentionMask)\n",
    "\n",
    "    new NDList(indicesArray, attentionMaskArray)\n",
    "  }\n",
    "\n",
    "  override def processOutput(ctx: TranslatorContext, list: NDList): Seq[PredictedToken] = {\n",
    "    val maskIndex = tokenList.zipWithIndex.find(_._1 == MaskToken).map(_._2).getOrElse(-1)\n",
    "    if (maskIndex == -1) {\n",
    "      Seq.empty[PredictedToken]\n",
    "    } else {\n",
    "      val ndArray = list.get(0)\n",
    "      val shape = ndArray.getShape\n",
    "      val len = shape.get(1)\n",
    "\n",
    "      (1 to TopK).map { i =>\n",
    "        val out = ndArray.get(maskIndex).argSort().getLong(len - i)\n",
    "        PredictedToken(vocabulary.getToken(out), ndArray.getFloat(maskIndex, out))\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  override def getBatchifier: Batchifier = Batchifier.STACK\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:     100% |████████████████████████████████████████|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[scala-interpreter-1] INFO ai.djl.pytorch.engine.PtEngine - Number of inter-op threads is 4\n",
      "[scala-interpreter-1] INFO ai.djl.pytorch.engine.PtEngine - Number of intra-op threads is 4\n",
      "[scala-interpreter-1] INFO ai.djl.huggingface.tokenizers.jni.LibUtils - Extracting native/lib/osx-x86_64/libtokenizers.dylib to cache ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictedToken(capital,18.19974136352539)\n",
      "PredictedToken(heart,10.769936561584473)\n",
      "PredictedToken(center,10.469231605529785)\n",
      "PredictedToken(centre,10.209856986999512)\n",
      "PredictedToken(city,9.985564231872559)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36minput\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"paris is the [MASK] of france.\"\u001b[39m\n",
       "\u001b[36mtranslator\u001b[39m: \u001b[32mHFBertFillMaskTranslator\u001b[39m = ammonite.$sess.cmd3$Helper$HFBertFillMaskTranslator@241526f0\n",
       "\u001b[36mcriteria\u001b[39m: \u001b[32mCriteria\u001b[39m[\u001b[32mString\u001b[39m, \u001b[32mSeq\u001b[39m[\u001b[32mPredictedToken\u001b[39m]] = Criteria:\n",
       "\tApplication: UNDEFINED\n",
       "\tInput: class java.lang.String\n",
       "\tOutput: interface scala.collection.Seq\n",
       "\tModelZoo: ai.djl.localmodelzoo\n",
       "\n",
       "\u001b[36mmodel\u001b[39m: \u001b[32mai\u001b[39m.\u001b[32mdjl\u001b[39m.\u001b[32mrepository\u001b[39m.\u001b[32mzoo\u001b[39m.\u001b[32mZooModel\u001b[39m[\u001b[32mString\u001b[39m, \u001b[32mSeq\u001b[39m[\u001b[32mPredictedToken\u001b[39m]] = ai.djl.repository.zoo.ZooModel@6b002e0e\n",
       "\u001b[36mpredictor\u001b[39m: \u001b[32mai\u001b[39m.\u001b[32mdjl\u001b[39m.\u001b[32minference\u001b[39m.\u001b[32mPredictor\u001b[39m[\u001b[32mString\u001b[39m, \u001b[32mSeq\u001b[39m[\u001b[32mPredictedToken\u001b[39m]] = ai.djl.inference.Predictor@c132fed\n",
       "\u001b[36mpredictResult\u001b[39m: \u001b[32mSeq\u001b[39m[\u001b[32mPredictedToken\u001b[39m] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mPredictedToken\u001b[39m(\u001b[32m\"capital\"\u001b[39m, \u001b[32m18.19974136352539\u001b[39m),\n",
       "  \u001b[33mPredictedToken\u001b[39m(\u001b[32m\"heart\"\u001b[39m, \u001b[32m10.769936561584473\u001b[39m),\n",
       "  \u001b[33mPredictedToken\u001b[39m(\u001b[32m\"center\"\u001b[39m, \u001b[32m10.469231605529785\u001b[39m),\n",
       "  \u001b[33mPredictedToken\u001b[39m(\u001b[32m\"centre\"\u001b[39m, \u001b[32m10.209856986999512\u001b[39m),\n",
       "  \u001b[33mPredictedToken\u001b[39m(\u001b[32m\"city\"\u001b[39m, \u001b[32m9.985564231872559\u001b[39m)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val input = \"Paris is the [MASK] of France.\".toLowerCase.replace(\"[mask]\", \"[MASK]\")\n",
    "\n",
    "val translator = new HFBertFillMaskTranslator()\n",
    "val criteria = Criteria.builder\n",
    "  .setTypes(classOf[String], classOf[Seq[PredictedToken]])\n",
    "  .optModelPath(Paths.get(\"../build/huggingface/fill_mask/pytorch/bert-base-uncased/\"))\n",
    "  .optTranslator(translator)\n",
    "  .optProgress(new ProgressBar)\n",
    "  .build\n",
    "\n",
    "val model = criteria.loadModel()\n",
    "\n",
    "val predictor = model.newPredictor(translator)\n",
    "\n",
    "val predictResult = predictor.predict(input)\n",
    "predictResult.foreach(println(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.12)",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
