{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Huggingface Pytorch Fill Mask Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upickle_2.12/0.9.5/upickle_2.12-0.9.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upickle_2.12/0.9.5/upickle_2.12-0.9.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upack_2.12/0.9.5/upack_2.12-0.9.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/ujson_2.12/0.9.5/ujson_2.12-0.9.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upickle-implicits_2.12/0.9.5/upickle-implicits_2.12-0.9.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upack_2.12/0.9.5/upack_2.12-0.9.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upickle-implicits_2.12/0.9.5/upickle-implicits_2.12-0.9.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/ujson_2.12/0.9.5/ujson_2.12-0.9.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upickle-core_2.12/0.9.5/upickle-core_2.12-0.9.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upickle-core_2.12/0.9.5/upickle-core_2.12-0.9.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upickle-core_2.12/0.9.5/upickle-core_2.12-0.9.5-sources.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upickle_2.12/0.9.5/upickle_2.12-0.9.5-sources.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upickle-implicits_2.12/0.9.5/upickle-implicits_2.12-0.9.5-sources.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/ujson_2.12/0.9.5/ujson_2.12-0.9.5.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upickle-core_2.12/0.9.5/upickle-core_2.12-0.9.5.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upickle_2.12/0.9.5/upickle_2.12-0.9.5.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upickle-core_2.12/0.9.5/upickle-core_2.12-0.9.5-sources.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upack_2.12/0.9.5/upack_2.12-0.9.5.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upickle-core_2.12/0.9.5/upickle-core_2.12-0.9.5.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upack_2.12/0.9.5/upack_2.12-0.9.5-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upickle_2.12/0.9.5/upickle_2.12-0.9.5-sources.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/ujson_2.12/0.9.5/ujson_2.12-0.9.5-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upickle-implicits_2.12/0.9.5/upickle-implicits_2.12-0.9.5-sources.jar\n",
      "Downloading https://repo1.maven.org/maven2/com/lihaoyi/upickle-implicits_2.12/0.9.5/upickle-implicits_2.12-0.9.5.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upack_2.12/0.9.5/upack_2.12-0.9.5.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upack_2.12/0.9.5/upack_2.12-0.9.5-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/ujson_2.12/0.9.5/ujson_2.12-0.9.5-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upickle-implicits_2.12/0.9.5/upickle-implicits_2.12-0.9.5.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/upickle_2.12/0.9.5/upickle_2.12-0.9.5.jar\n",
      "Downloaded https://repo1.maven.org/maven2/com/lihaoyi/ujson_2.12/0.9.5/ujson_2.12-0.9.5.jar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                  \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                     \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                        \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                     \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                           \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                              \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                           \u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`ai.djl:api:0.17.0`\n",
    "import $ivy.`ai.djl.huggingface:tokenizers:0.17.0`\n",
    "import $ivy.`ai.djl.pytorch:pytorch-model-zoo:0.17.0`\n",
    "import $ivy.`ai.djl.pytorch:pytorch-engine:0.17.0`\n",
    "import $ivy.`org.slf4j:slf4j-api:1.7.36`\n",
    "import $ivy.`org.slf4j:slf4j-simple:1.7.36`\n",
    "import $ivy.`com.lihaoyi::upickle:0.9.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io.IOException\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.file.{Files, Paths}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.util\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.modality.Classifications\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.modality.nlp.DefaultVocabulary\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.modality.nlp.bert.BertTokenizer\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.modality.nlp.Vocabulary\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.ndarray.NDList\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.repository.zoo.Criteria\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.training.util.{DownloadUtils, ProgressBar}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.translate.{Batchifier, Translator, TranslatorContext}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.huggingface.tokenizers.HuggingFaceTokenizer\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.io.IOException\n",
    "import java.nio.file.{Files, Paths}\n",
    "import java.util\n",
    "\n",
    "import ai.djl.modality.Classifications\n",
    "import ai.djl.modality.nlp.DefaultVocabulary\n",
    "import ai.djl.modality.nlp.bert.BertTokenizer\n",
    "import ai.djl.modality.nlp.Vocabulary\n",
    "import ai.djl.ndarray.NDList\n",
    "import ai.djl.repository.zoo.Criteria\n",
    "import ai.djl.training.util.{DownloadUtils, ProgressBar}\n",
    "import ai.djl.translate.{Batchifier, Translator, TranslatorContext}\n",
    "import ai.djl.huggingface.tokenizers.HuggingFaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mPredictedLabel\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class PredictedLabel(label: String, score: Double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mHFBertFillMaskTranslator\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class HFZeroShotClsTranslator extends Translator[String, Seq[PredictedLabel]] {\n",
    "\n",
    "  private var vocabulary: DefaultVocabulary = _\n",
    "  private var tokenizer: HuggingFaceTokenizer = _\n",
    "  private var tokenList: Array[String] = _\n",
    "\n",
    "  override def prepare(ctx: TranslatorContext): Unit = {\n",
    "    val path = Paths.get(\"../build/huggingface/zero-shot-classification/pytorch/bart-large-mnli/vocab.txt\")\n",
    "    vocabulary = DefaultVocabulary.builder\n",
    "      .optMinFrequency(1)\n",
    "      .addFromTextFile(path)\n",
    "      .optUnknownToken(\"<unk>\")\n",
    "      .build\n",
    "    tokenizer = HuggingFaceTokenizer.newInstance(\"facebook/bart-large-mnli\")\n",
    "  }\n",
    "\n",
    "  override def processInput(ctx: TranslatorContext, input: String): NDList = {\n",
    "    val token = tokenizer.encode(input.toLowerCase().replace(MaskToken.toLowerCase(), MaskToken))\n",
    "    // get the encoded tokens that would be used in precessOutput\n",
    "    tokenList = token.getTokens\n",
    "    // map the tokens(String) to indices(long)\n",
    "\n",
    "    val manager = ctx.getNDManager\n",
    "    val indices = tokenList.map(vocabulary.getIndex)\n",
    "    val attentionMask = token.getAttentionMask.map(i => i)\n",
    "    val indicesArray = manager.create(indices)\n",
    "    val attentionMaskArray = manager.create(attentionMask)\n",
    "\n",
    "    new NDList(indicesArray, attentionMaskArray)\n",
    "  }\n",
    "\n",
    "  override def processOutput(ctx: TranslatorContext, list: NDList): Seq[PredictedToken] = {\n",
    "    val maskIndex = tokenList.zipWithIndex.find(_._1 == MaskToken).map(_._2).getOrElse(-1)\n",
    "    if (maskIndex == -1) {\n",
    "      Seq.empty[PredictedToken]\n",
    "    } else {\n",
    "      val ndArray = list.get(0)\n",
    "      val shape = ndArray.getShape\n",
    "      val len = shape.get(1)\n",
    "\n",
    "      (1 to TopK).map { i =>\n",
    "        val out = ndArray.get(maskIndex).argSort().getLong(len - i)\n",
    "        PredictedToken(vocabulary.getToken(out), ndArray.getFloat(maskIndex, out))\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  override def getBatchifier: Batchifier = Batchifier.STACK\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:     100% |████████████████████████████████████████|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[scala-interpreter-1] INFO ai.djl.pytorch.engine.PtEngine - Number of inter-op threads is 4\n",
      "[scala-interpreter-1] INFO ai.djl.pytorch.engine.PtEngine - Number of intra-op threads is 4\n",
      "[scala-interpreter-1] INFO ai.djl.huggingface.tokenizers.jni.LibUtils - Extracting native/lib/osx-x86_64/libtokenizers.dylib to cache ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictedToken(capital,18.19974136352539)\n",
      "PredictedToken(heart,10.769936561584473)\n",
      "PredictedToken(center,10.469231605529785)\n",
      "PredictedToken(centre,10.209856986999512)\n",
      "PredictedToken(city,9.985564231872559)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36minput\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"paris is the [MASK] of france.\"\u001b[39m\n",
       "\u001b[36mtranslator\u001b[39m: \u001b[32mHFBertFillMaskTranslator\u001b[39m = ammonite.$sess.cmd3$Helper$HFBertFillMaskTranslator@241526f0\n",
       "\u001b[36mcriteria\u001b[39m: \u001b[32mCriteria\u001b[39m[\u001b[32mString\u001b[39m, \u001b[32mSeq\u001b[39m[\u001b[32mPredictedToken\u001b[39m]] = Criteria:\n",
       "\tApplication: UNDEFINED\n",
       "\tInput: class java.lang.String\n",
       "\tOutput: interface scala.collection.Seq\n",
       "\tModelZoo: ai.djl.localmodelzoo\n",
       "\n",
       "\u001b[36mmodel\u001b[39m: \u001b[32mai\u001b[39m.\u001b[32mdjl\u001b[39m.\u001b[32mrepository\u001b[39m.\u001b[32mzoo\u001b[39m.\u001b[32mZooModel\u001b[39m[\u001b[32mString\u001b[39m, \u001b[32mSeq\u001b[39m[\u001b[32mPredictedToken\u001b[39m]] = ai.djl.repository.zoo.ZooModel@6b002e0e\n",
       "\u001b[36mpredictor\u001b[39m: \u001b[32mai\u001b[39m.\u001b[32mdjl\u001b[39m.\u001b[32minference\u001b[39m.\u001b[32mPredictor\u001b[39m[\u001b[32mString\u001b[39m, \u001b[32mSeq\u001b[39m[\u001b[32mPredictedToken\u001b[39m]] = ai.djl.inference.Predictor@c132fed\n",
       "\u001b[36mpredictResult\u001b[39m: \u001b[32mSeq\u001b[39m[\u001b[32mPredictedToken\u001b[39m] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mPredictedToken\u001b[39m(\u001b[32m\"capital\"\u001b[39m, \u001b[32m18.19974136352539\u001b[39m),\n",
       "  \u001b[33mPredictedToken\u001b[39m(\u001b[32m\"heart\"\u001b[39m, \u001b[32m10.769936561584473\u001b[39m),\n",
       "  \u001b[33mPredictedToken\u001b[39m(\u001b[32m\"center\"\u001b[39m, \u001b[32m10.469231605529785\u001b[39m),\n",
       "  \u001b[33mPredictedToken\u001b[39m(\u001b[32m\"centre\"\u001b[39m, \u001b[32m10.209856986999512\u001b[39m),\n",
       "  \u001b[33mPredictedToken\u001b[39m(\u001b[32m\"city\"\u001b[39m, \u001b[32m9.985564231872559\u001b[39m)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val input = \"Paris is the [MASK] of France.\".toLowerCase.replace(\"[mask]\", \"[MASK]\")\n",
    "\n",
    "val translator = new HFBertFillMaskTranslator()\n",
    "val criteria = Criteria.builder\n",
    "  .setTypes(classOf[String], classOf[Seq[PredictedToken]])\n",
    "  .optModelPath(Paths.get(\"../build/huggingface/fill_mask/pytorch/bert-base-uncased/\"))\n",
    "  .optTranslator(translator)\n",
    "  .optProgress(new ProgressBar)\n",
    "  .build\n",
    "\n",
    "val model = criteria.loadModel()\n",
    "\n",
    "val predictor = model.newPredictor(translator)\n",
    "\n",
    "val predictResult = predictor.predict(input)\n",
    "predictResult.foreach(println(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mencoded\u001b[39m: \u001b[32mSeq\u001b[39m[\u001b[32mInt\u001b[39m] = \u001b[33mList\u001b[39m(\n",
       "  \u001b[32m0\u001b[39m,\n",
       "  \u001b[32m10285\u001b[39m,\n",
       "  \u001b[32m186\u001b[39m,\n",
       "  \u001b[32m38\u001b[39m,\n",
       "  \u001b[32m7084\u001b[39m,\n",
       "  \u001b[32m127\u001b[39m,\n",
       "  \u001b[32m6894\u001b[39m,\n",
       "  \u001b[32m1732\u001b[39m,\n",
       "  \u001b[32m8\u001b[39m,\n",
       "  \u001b[32m655\u001b[39m,\n",
       "  \u001b[32m187\u001b[39m,\n",
       "  \u001b[32m172\u001b[39m,\n",
       "  \u001b[32m127\u001b[39m,\n",
       "  \u001b[32m1028\u001b[39m,\n",
       "  \u001b[32m34\u001b[39m,\n",
       "  \u001b[32m57\u001b[39m,\n",
       "  \u001b[32m27169\u001b[39m,\n",
       "  \u001b[32m1295\u001b[39m,\n",
       "  \u001b[32m8378\u001b[39m,\n",
       "  \u001b[32m38\u001b[39m,\n",
       "  \u001b[32m304\u001b[39m,\n",
       "  \u001b[32m110\u001b[39m,\n",
       "  \u001b[32m1553\u001b[39m,\n",
       "  \u001b[32m4\u001b[39m,\n",
       "  \u001b[32m2\u001b[39m,\n",
       "  \u001b[32m2\u001b[39m,\n",
       "  \u001b[32m713\u001b[39m,\n",
       "  \u001b[32m1246\u001b[39m,\n",
       "  \u001b[32m16\u001b[39m,\n",
       "  \u001b[32m1830\u001b[39m,\n",
       "  \u001b[32m4\u001b[39m,\n",
       "  \u001b[32m2\u001b[39m\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val encoded = Seq( 0, 10285,   186,    38,  7084,   127,  6894,  1732,     8,   655,\n",
    "           187,   172,   127,  1028,    34,    57, 27169,  1295,  8378,    38,\n",
    "           304,   110,  1553,     4,     2,     2,   713,  1246,    16,  1830,\n",
    "             4,     2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mpath\u001b[39m: \u001b[32mjava\u001b[39m.\u001b[32mnio\u001b[39m.\u001b[32mfile\u001b[39m.\u001b[32mPath\u001b[39m = ../build/huggingface/zero-shot-classification/pytorch/bart-large-mnli/vocab.txt\n",
       "\u001b[36mvocabulary\u001b[39m: \u001b[32mDefaultVocabulary\u001b[39m = ai.djl.modality.nlp.DefaultVocabulary@5f16d5d7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val path = Paths.get(\"../build/huggingface/zero-shot-classification/pytorch/bart-large-mnli/vocab.txt\")\n",
    "val vocabulary = DefaultVocabulary.builder\n",
    "      .optMinFrequency(1)\n",
    "      .addFromTextFile(path)\n",
    "      .optUnknownToken(\"<unk>\")\n",
    "      .build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>\n",
      "Last\n",
      "Ġweek\n",
      "ĠI\n",
      "Ġupgraded\n",
      "Ġmy\n",
      "ĠiOS\n",
      "Ġversion\n",
      "Ġand\n",
      "Ġever\n",
      "Ġsince\n",
      "Ġthen\n",
      "Ġmy\n",
      "Ġphone\n",
      "Ġhas\n",
      "Ġbeen\n",
      "Ġoverhe\n",
      "ating\n",
      "Ġwhenever\n",
      "ĠI\n",
      "Ġuse\n",
      "Ġyour\n",
      "Ġapp\n",
      ".\n",
      "</s>\n",
      "</s>\n",
      "This\n",
      "Ġexample\n",
      "Ġis\n",
      "Ġmobile\n",
      ".\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "encoded.foreach(r => println(vocabulary.getToken(r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtokenizer\u001b[39m: \u001b[32mHuggingFaceTokenizer\u001b[39m = ai.djl.huggingface.tokenizers.HuggingFaceTokenizer@7d7db9a3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tokenizer = HuggingFaceTokenizer.newInstance(\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mpremise\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"Last week I upgraded my iOS version and ever since then my phone has been overheating whenever I use your app.\"\u001b[39m\n",
       "\u001b[36mlabels\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mArray\u001b[39m(\u001b[32m\"mobile\"\u001b[39m, \u001b[32m\"website\"\u001b[39m, \u001b[32m\"billing\"\u001b[39m, \u001b[32m\"account access\"\u001b[39m)\n",
       "\u001b[36mhypothesis\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"This example is mobile.\"\u001b[39m\n",
       "\u001b[36mres20_3\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mArray\u001b[39m(\n",
       "  \u001b[32m\"<s>\"\u001b[39m,\n",
       "  \u001b[32m\"Last\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120week\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120I\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120upgraded\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120my\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120iOS\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120version\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120and\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120ever\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120since\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120then\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120my\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120phone\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120has\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120been\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120overhe\"\u001b[39m,\n",
       "  \u001b[32m\"ating\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120whenever\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120I\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120use\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120your\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120app\"\u001b[39m,\n",
       "  \u001b[32m\".\"\u001b[39m,\n",
       "  \u001b[32m\"</s>\"\u001b[39m,\n",
       "  \u001b[32m\"</s>\"\u001b[39m,\n",
       "  \u001b[32m\"This\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120example\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120is\"\u001b[39m,\n",
       "  \u001b[32m\"\\u0120mobile\"\u001b[39m,\n",
       "  \u001b[32m\".\"\u001b[39m,\n",
       "  \u001b[32m\"</s>\"\u001b[39m\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val premise = \"Last week I upgraded my iOS version and ever since then my phone has been overheating whenever I use your app.\"\n",
    "val labels = Array(\"mobile\", \"website\", \"billing\", \"account access\")\n",
    "val hypothesis = s\"This example is ${labels(0)}.\"\n",
    "tokenizer.encode(Array(premise, \"</s>\", \"</s>\", hypothesis)).getTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>\n",
      "Last\n",
      "Ġweek\n",
      "ĠI\n",
      "Ġupgraded\n",
      "Ġmy\n",
      "ĠiOS\n",
      "Ġversion\n",
      "Ġand\n",
      "Ġever\n",
      "Ġsince\n",
      "Ġthen\n",
      "Ġmy\n",
      "Ġphone\n",
      "Ġhas\n",
      "Ġbeen\n",
      "Ġoverhe\n",
      "ating\n",
      "Ġwhenever\n",
      "ĠI\n",
      "Ġuse\n",
      "Ġyour\n",
      "Ġapp\n",
      ".\n",
      "</s>\n",
      "</s>\n",
      "This\n",
      "Ġexample\n",
      "Ġis\n",
      "Ġmobile\n",
      ".\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "encoded.foreach(r => println(vocabulary.getToken(r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.12)",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
