{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Huggingface Question Answering Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                  \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                     \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                        \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                     \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                           \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                              \u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`ai.djl:api:0.17.0`\n",
    "import $ivy.`ai.djl.huggingface:tokenizers:0.17.0`\n",
    "import $ivy.`ai.djl.pytorch:pytorch-model-zoo:0.17.0`\n",
    "import $ivy.`ai.djl.pytorch:pytorch-engine:0.17.0`\n",
    "import $ivy.`org.slf4j:slf4j-api:1.7.36`\n",
    "import $ivy.`org.slf4j:slf4j-simple:1.7.36`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io.IOException\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.file.{Files, Paths}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.util\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.modality.Classifications\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.modality.nlp.DefaultVocabulary\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.modality.nlp.bert.BertTokenizer\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.modality.nlp.Vocabulary\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.ndarray.NDList\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.repository.zoo.Criteria\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.training.util.{DownloadUtils, ProgressBar}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.translate.{Batchifier, Translator, TranslatorContext}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.huggingface.tokenizers.HuggingFaceTokenizer\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.io.IOException\n",
    "import java.nio.file.{Files, Paths}\n",
    "import java.util\n",
    "\n",
    "import ai.djl.modality.Classifications\n",
    "import ai.djl.modality.nlp.DefaultVocabulary\n",
    "import ai.djl.modality.nlp.bert.BertTokenizer\n",
    "import ai.djl.modality.nlp.Vocabulary\n",
    "import ai.djl.ndarray.NDList\n",
    "import ai.djl.repository.zoo.Criteria\n",
    "import ai.djl.training.util.{DownloadUtils, ProgressBar}\n",
    "import ai.djl.translate.{Batchifier, Translator, TranslatorContext}\n",
    "import ai.djl.huggingface.tokenizers.HuggingFaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mPredictedToken\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class PredictedToken(token: String, score: Double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mHFBertFillMaskTranslator\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class HFBertFillMaskTranslator extends Translator[String, Seq[PredictedToken]] {\n",
    "\n",
    "  private var vocabulary: DefaultVocabulary = _\n",
    "  private var tokenizer: HuggingFaceTokenizer = _\n",
    "  private var tokenList: Array[String] = _\n",
    "  private final val MaskToken = \"[MASK]\"\n",
    "  private final val TopK = 5\n",
    "\n",
    "  override def prepare(ctx: TranslatorContext): Unit = {\n",
    "    val path = Paths.get(\"build/huggingface/fill_mask/pytorch/bert-base-uncased/vocab.txt\")\n",
    "    vocabulary = DefaultVocabulary.builder\n",
    "      .optMinFrequency(1)\n",
    "      .addFromTextFile(path)\n",
    "      .optUnknownToken(\"[UNK]\")\n",
    "      .build\n",
    "    tokenizer = HuggingFaceTokenizer.newInstance(\"bert-base-uncased\")\n",
    "  }\n",
    "\n",
    "  override def processInput(ctx: TranslatorContext, input: String): NDList = {\n",
    "    val token = tokenizer.encode(input.toLowerCase().replace(MaskToken.toLowerCase(), MaskToken))\n",
    "    // get the encoded tokens that would be used in precessOutput\n",
    "    tokenList = token.getTokens\n",
    "    // map the tokens(String) to indices(long)\n",
    "\n",
    "    val manager = ctx.getNDManager\n",
    "    val indices = tokenList.map(vocabulary.getIndex)\n",
    "    val attentionMask = token.getAttentionMask.map(i => i)\n",
    "    val indicesArray = manager.create(indices)\n",
    "    val attentionMaskArray = manager.create(attentionMask)\n",
    "\n",
    "    new NDList(indicesArray, attentionMaskArray)\n",
    "  }\n",
    "\n",
    "  override def processOutput(ctx: TranslatorContext, list: NDList): Seq[PredictedToken] = {\n",
    "    val maskIndex = tokenList.zipWithIndex.find(_._1 == MaskToken).map(_._2).getOrElse(-1)\n",
    "    if (maskIndex == -1) {\n",
    "      Seq.empty[PredictedToken]\n",
    "    } else {\n",
    "      val ndArray = list.get(0)\n",
    "      val shape = ndArray.getShape\n",
    "      val len = shape.get(1)\n",
    "\n",
    "      (1 to TopK).map { i =>\n",
    "        val out = ndArray.get(maskIndex).argSort().getLong(len - i)\n",
    "        PredictedToken(vocabulary.getToken(out), ndArray.getFloat(maskIndex, out))\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  override def getBatchifier: Batchifier = Batchifier.STACK\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:     100% |████████████████████████████████████████|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[scala-interpreter-1] INFO ai.djl.pytorch.engine.PtEngine - Number of inter-op threads is 4\n",
      "[scala-interpreter-1] INFO ai.djl.pytorch.engine.PtEngine - Number of intra-op threads is 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictedToken(capital,18.19974136352539)\n",
      "PredictedToken(heart,10.769936561584473)\n",
      "PredictedToken(center,10.469231605529785)\n",
      "PredictedToken(centre,10.209856986999512)\n",
      "PredictedToken(city,9.985564231872559)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36minput\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"paris is the [MASK] of france.\"\u001b[39m\n",
       "\u001b[36mtranslator\u001b[39m: \u001b[32mHFBertFillMaskTranslator\u001b[39m = ammonite.$sess.cmd3$Helper$HFBertFillMaskTranslator@56774091\n",
       "\u001b[36mcriteria\u001b[39m: \u001b[32mCriteria\u001b[39m[\u001b[32mString\u001b[39m, \u001b[32mSeq\u001b[39m[\u001b[32mPredictedToken\u001b[39m]] = Criteria:\n",
       "\tApplication: UNDEFINED\n",
       "\tInput: class java.lang.String\n",
       "\tOutput: interface scala.collection.Seq\n",
       "\tModelZoo: ai.djl.localmodelzoo\n",
       "\n",
       "\u001b[36mmodel\u001b[39m: \u001b[32mai\u001b[39m.\u001b[32mdjl\u001b[39m.\u001b[32mrepository\u001b[39m.\u001b[32mzoo\u001b[39m.\u001b[32mZooModel\u001b[39m[\u001b[32mString\u001b[39m, \u001b[32mSeq\u001b[39m[\u001b[32mPredictedToken\u001b[39m]] = ai.djl.repository.zoo.ZooModel@5ab918f6\n",
       "\u001b[36mpredictor\u001b[39m: \u001b[32mai\u001b[39m.\u001b[32mdjl\u001b[39m.\u001b[32minference\u001b[39m.\u001b[32mPredictor\u001b[39m[\u001b[32mString\u001b[39m, \u001b[32mSeq\u001b[39m[\u001b[32mPredictedToken\u001b[39m]] = ai.djl.inference.Predictor@51b24605\n",
       "\u001b[36mpredictResult\u001b[39m: \u001b[32mSeq\u001b[39m[\u001b[32mPredictedToken\u001b[39m] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mPredictedToken\u001b[39m(\u001b[32m\"capital\"\u001b[39m, \u001b[32m18.19974136352539\u001b[39m),\n",
       "  \u001b[33mPredictedToken\u001b[39m(\u001b[32m\"heart\"\u001b[39m, \u001b[32m10.769936561584473\u001b[39m),\n",
       "  \u001b[33mPredictedToken\u001b[39m(\u001b[32m\"center\"\u001b[39m, \u001b[32m10.469231605529785\u001b[39m),\n",
       "  \u001b[33mPredictedToken\u001b[39m(\u001b[32m\"centre\"\u001b[39m, \u001b[32m10.209856986999512\u001b[39m),\n",
       "  \u001b[33mPredictedToken\u001b[39m(\u001b[32m\"city\"\u001b[39m, \u001b[32m9.985564231872559\u001b[39m)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val input = \"Paris is the [MASK] of France.\".toLowerCase.replace(\"[mask]\", \"[MASK]\")\n",
    "\n",
    "val translator = new HFBertFillMaskTranslator()\n",
    "val criteria = Criteria.builder\n",
    "  .setTypes(classOf[String], classOf[Seq[PredictedToken]])\n",
    "  .optModelPath(Paths.get(\"build/huggingface/fill_mask/pytorch/bert-base-uncased/\"))\n",
    "  .optTranslator(translator)\n",
    "  .optProgress(new ProgressBar)\n",
    "  .build\n",
    "\n",
    "val model = criteria.loadModel()\n",
    "\n",
    "val predictor = model.newPredictor(translator)\n",
    "\n",
    "val predictResult = predictor.predict(input)\n",
    "predictResult.foreach(println(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.12)",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
