{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Huggingface Question Answering Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                  \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                     \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                              \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                           \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                           \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                              \u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`ai.djl:api:0.17.0`\n",
    "import $ivy.`ai.djl.huggingface:tokenizers:0.17.0`\n",
    "import $ivy.`ai.djl.tensorflow:tensorflow-model-zoo:0.17.0`\n",
    "import $ivy.`ai.djl.tensorflow:tensorflow-engine:0.17.0`\n",
    "import $ivy.`org.slf4j:slf4j-api:1.7.36`\n",
    "import $ivy.`org.slf4j:slf4j-simple:1.7.36`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io.IOException\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.file.{Files, Paths}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.util\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.modality.Classifications\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.modality.nlp.DefaultVocabulary\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.modality.nlp.bert.BertTokenizer\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.modality.nlp.Vocabulary\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.ndarray.NDList\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.repository.zoo.Criteria\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.training.util.{DownloadUtils, ProgressBar}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.translate.{Batchifier, Translator, TranslatorContext}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mai.djl.huggingface.tokenizers.HuggingFaceTokenizer\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.io.IOException\n",
    "import java.nio.file.{Files, Paths}\n",
    "import java.util\n",
    "\n",
    "import ai.djl.modality.Classifications\n",
    "import ai.djl.modality.nlp.DefaultVocabulary\n",
    "import ai.djl.modality.nlp.bert.BertTokenizer\n",
    "import ai.djl.modality.nlp.Vocabulary\n",
    "import ai.djl.ndarray.NDList\n",
    "import ai.djl.repository.zoo.Criteria\n",
    "import ai.djl.training.util.{DownloadUtils, ProgressBar}\n",
    "import ai.djl.translate.{Batchifier, Translator, TranslatorContext}\n",
    "import ai.djl.huggingface.tokenizers.HuggingFaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mPredictedToken\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class PredictedToken(token: String, score: Double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mHFBertFillMaskTranslator\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class HFBertFillMaskTranslator extends Translator[String, Seq[PredictedToken]] {\n",
    "\n",
    "  private var vocabulary: DefaultVocabulary = _\n",
    "  private var tokenizer: HuggingFaceTokenizer = _\n",
    "  private var tokenList: Array[String] = _\n",
    "  private final val MaskToken = \"[MASK]\"\n",
    "  private final val TopK = 5\n",
    "\n",
    "  override def prepare(ctx: TranslatorContext): Unit = {\n",
    "    val path = Paths.get(\"build/huggingface/fill_mask/tensorflow/bert-base-uncased/vocab.txt\")\n",
    "    vocabulary = DefaultVocabulary.builder\n",
    "      .optMinFrequency(1)\n",
    "      .addFromTextFile(path)\n",
    "      .optUnknownToken(\"[UNK]\")\n",
    "      .build\n",
    "    tokenizer = HuggingFaceTokenizer.newInstance(\"bert-base-uncased\")\n",
    "  }\n",
    "\n",
    "  override def processInput(ctx: TranslatorContext, input: String): NDList = {\n",
    "    val token = tokenizer.encode(input.toLowerCase().replace(MaskToken.toLowerCase(), MaskToken))\n",
    "    // get the encoded tokens that would be used in precessOutput\n",
    "    tokenList = token.getTokens\n",
    "    // map the tokens(String) to indices(long)\n",
    "\n",
    "    val manager = ctx.getNDManager\n",
    "    val indices = tokenList.map(vocabulary.getIndex)\n",
    "    val attentionMask = token.getAttentionMask.map(i => i)\n",
    "    val indicesArray = manager.create(indices)\n",
    "    val attentionMaskArray = manager.create(attentionMask)\n",
    "\n",
    "    new NDList(indicesArray, attentionMaskArray)\n",
    "  }\n",
    "\n",
    "  override def processOutput(ctx: TranslatorContext, list: NDList): Seq[PredictedToken] = {\n",
    "    val maskIndex = tokenList.zipWithIndex.find(_._1 == MaskToken).map(_._2).getOrElse(-1)\n",
    "    if (maskIndex == -1) {\n",
    "      Seq.empty[PredictedToken]\n",
    "    } else {\n",
    "      val ndArray = list.get(0)\n",
    "      val shape = ndArray.getShape\n",
    "      val len = shape.get(1)\n",
    "\n",
    "      (1 to TopK).map { i =>\n",
    "        val out = ndArray.get(maskIndex).argSort().getLong(len - i)\n",
    "        PredictedToken(vocabulary.getToken(out), ndArray.getFloat(maskIndex, out))\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  override def getBatchifier: Batchifier = Batchifier.STACK\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:     100% |████████████████████████████████████████|\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31mai.djl.translate.TranslateException: org.tensorflow.exceptions.TFInvalidArgumentException: Expects arg[0] to be int32 but int64 is provided\u001b[39m\n  ai.djl.inference.Predictor.batchPredict(\u001b[32mPredictor.java\u001b[39m:\u001b[32m187\u001b[39m)\n  ai.djl.inference.Predictor.predict(\u001b[32mPredictor.java\u001b[39m:\u001b[32m124\u001b[39m)\n  ammonite.$sess.cmd4$Helper.<init>(\u001b[32mcmd4.sc\u001b[39m:\u001b[32m15\u001b[39m)\n  ammonite.$sess.cmd4$.<init>(\u001b[32mcmd4.sc\u001b[39m:\u001b[32m7\u001b[39m)\n  ammonite.$sess.cmd4$.<clinit>(\u001b[32mcmd4.sc\u001b[39m:\u001b[32m-1\u001b[39m)\n\u001b[31morg.tensorflow.exceptions.TFInvalidArgumentException: Expects arg[0] to be int32 but int64 is provided\u001b[39m\n  org.tensorflow.internal.c_api.AbstractTF_Status.throwExceptionIfNotOK(\u001b[32mAbstractTF_Status.java\u001b[39m:\u001b[32m87\u001b[39m)\n  ai.djl.tensorflow.engine.javacpp.JavacppUtils.runSession(\u001b[32mJavacppUtils.java\u001b[39m:\u001b[32m193\u001b[39m)\n  ai.djl.tensorflow.engine.TfSymbolBlock.forwardInternal(\u001b[32mTfSymbolBlock.java\u001b[39m:\u001b[32m129\u001b[39m)\n  ai.djl.nn.AbstractBaseBlock.forward(\u001b[32mAbstractBaseBlock.java\u001b[39m:\u001b[32m76\u001b[39m)\n  ai.djl.nn.Block.forward(\u001b[32mBlock.java\u001b[39m:\u001b[32m122\u001b[39m)\n  ai.djl.inference.Predictor.predictInternal(\u001b[32mPredictor.java\u001b[39m:\u001b[32m138\u001b[39m)\n  ai.djl.inference.Predictor.batchPredict(\u001b[32mPredictor.java\u001b[39m:\u001b[32m178\u001b[39m)\n  ai.djl.inference.Predictor.predict(\u001b[32mPredictor.java\u001b[39m:\u001b[32m124\u001b[39m)\n  ammonite.$sess.cmd4$Helper.<init>(\u001b[32mcmd4.sc\u001b[39m:\u001b[32m15\u001b[39m)\n  ammonite.$sess.cmd4$.<init>(\u001b[32mcmd4.sc\u001b[39m:\u001b[32m7\u001b[39m)\n  ammonite.$sess.cmd4$.<clinit>(\u001b[32mcmd4.sc\u001b[39m:\u001b[32m-1\u001b[39m)"
     ]
    }
   ],
   "source": [
    "val input = \"Paris is the [MASK] of France.\".toLowerCase.replace(\"[mask]\", \"[MASK]\")\n",
    "\n",
    "val translator = new HFBertFillMaskTranslator()\n",
    "val criteria = Criteria.builder\n",
    "  .setTypes(classOf[String], classOf[Seq[PredictedToken]])\n",
    "  .optModelPath(Paths.get(\"build/huggingface/fill_mask/tensorflow/bert-base-uncased/\"))\n",
    "  .optTranslator(translator)\n",
    "  .optProgress(new ProgressBar)\n",
    "  .build\n",
    "\n",
    "val model = criteria.loadModel()\n",
    "\n",
    "val predictor = model.newPredictor(translator)\n",
    "\n",
    "val predictResult = predictor.predict(input)\n",
    "predictResult.foreach(println(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.12)",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
